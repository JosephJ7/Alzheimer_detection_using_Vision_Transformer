{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import random\nimport math\nimport pandas as pd\nimport numpy as np\n# for visualizations\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n# for image related operations\nimport PIL\n# for warnings\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-02T08:12:03.656018Z","iopub.execute_input":"2022-04-02T08:12:03.656672Z","iopub.status.idle":"2022-04-02T08:12:04.581024Z","shell.execute_reply.started":"2022-04-02T08:12:03.656560Z","shell.execute_reply":"2022-04-02T08:12:04.580151Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\n\n# importing data\ndata_path = \"../input/alzheimer-augmented/AG_Alzheimer_s Dataset\"\nbatch_size = 64 # can use 32 or 128 as well\n\n# tf.keras.preprocessing.image_dataset_from_directory generates a tf.data.Dataset from image files in a directory\ndata = tf.keras.preprocessing.image_dataset_from_directory(data_path, label_mode = None, image_size = (64,64), batch_size = batch_size)","metadata":{"execution":{"iopub.status.busy":"2022-04-02T08:14:28.164931Z","iopub.execute_input":"2022-04-02T08:14:28.165217Z","iopub.status.idle":"2022-04-02T08:14:36.597762Z","shell.execute_reply.started":"2022-04-02T08:14:28.165186Z","shell.execute_reply":"2022-04-02T08:14:36.597080Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"type(data)","metadata":{"execution":{"iopub.status.busy":"2022-04-02T08:15:07.912466Z","iopub.execute_input":"2022-04-02T08:15:07.912892Z","iopub.status.idle":"2022-04-02T08:15:07.927611Z","shell.execute_reply.started":"2022-04-02T08:15:07.912850Z","shell.execute_reply":"2022-04-02T08:15:07.926627Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(15,15)) # (15, 15) is the size of each image\nfor images in data.take(1):\n    for i in range(10): # display 10 images\n        ax = plt.subplot(6, 5, i + 1) # 6 rows, 5 columns for the i+1th image (i starts from 0 hence 1 is added)\n        \n        # dataset needs to be first converted to numpy array to be displayed. unit8 has range from 0 to 255 which fits perfectly for our image data, hence this is used\n        ax.imshow(images[i].numpy().astype(\"uint8\")) \n        ax.axis(\"off\")","metadata":{"execution":{"iopub.status.busy":"2022-04-02T08:17:13.396588Z","iopub.execute_input":"2022-04-02T08:17:13.396843Z","iopub.status.idle":"2022-04-02T08:17:14.215129Z","shell.execute_reply.started":"2022-04-02T08:17:13.396815Z","shell.execute_reply":"2022-04-02T08:17:14.214458Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"data = data.map(lambda x: x / 255.0)\ndata","metadata":{"execution":{"iopub.status.busy":"2022-04-02T08:18:49.612791Z","iopub.execute_input":"2022-04-02T08:18:49.613061Z","iopub.status.idle":"2022-04-02T08:18:49.639023Z","shell.execute_reply.started":"2022-04-02T08:18:49.613032Z","shell.execute_reply":"2022-04-02T08:18:49.638371Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"from PIL import Image\nimport tensorflow  as tf\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Reshape, UpSampling2D, Conv2D, BatchNormalization\nfrom tensorflow.keras.layers import LeakyReLU, Dropout, ZeroPadding2D, Flatten, Activation\nfrom tensorflow.keras.optimizers import Adam","metadata":{"execution":{"iopub.status.busy":"2022-04-02T08:19:05.287761Z","iopub.execute_input":"2022-04-02T08:19:05.288032Z","iopub.status.idle":"2022-04-02T08:19:05.296945Z","shell.execute_reply.started":"2022-04-02T08:19:05.288002Z","shell.execute_reply":"2022-04-02T08:19:05.295956Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"latent_dim = 100\n\n# building a generator\ngenerator = Sequential()\ngenerator.add(Dense(4*4*256, activation=\"relu\", input_dim=latent_dim))\ngenerator.add(Reshape((4,4,256)))\ngenerator.add(UpSampling2D())\ngenerator.add(Conv2D(256,kernel_size=3,padding=\"same\"))\ngenerator.add(BatchNormalization(momentum=0.8))\ngenerator.add(Activation(\"relu\"))\ngenerator.add(UpSampling2D())\ngenerator.add(Conv2D(256,kernel_size=3,padding=\"same\"))\ngenerator.add(BatchNormalization(momentum=0.8))\ngenerator.add(Activation(\"relu\"))\ngenerator.add(UpSampling2D())\ngenerator.add(Conv2D(256,kernel_size=3,padding=\"same\"))#\ngenerator.add(BatchNormalization(momentum=0.8))\ngenerator.add(Activation(\"relu\"))\ngenerator.add(UpSampling2D())\ngenerator.add(Conv2D(128,kernel_size=3,padding=\"same\"))\ngenerator.add(BatchNormalization(momentum=0.8))\ngenerator.add(Activation(\"relu\"))\ngenerator.add(Conv2D(3,kernel_size=3,padding=\"same\"))\ngenerator.add(Activation(\"tanh\")) \n\ngenerator.summary()","metadata":{"execution":{"iopub.status.busy":"2022-04-02T08:19:29.193011Z","iopub.execute_input":"2022-04-02T08:19:29.193741Z","iopub.status.idle":"2022-04-02T08:19:29.374195Z","shell.execute_reply.started":"2022-04-02T08:19:29.193699Z","shell.execute_reply":"2022-04-02T08:19:29.373513Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# creating a random noise and output from generator\nnoise = tf.random.normal([1, latent_dim]) # 1 image of latent_dim size = 100\nGenerated_image = generator(noise, training=False) # generate image from the random noise\n\n# plotting the image output of generator without training \nplt.imshow(Generated_image[0, :, :, 0])\nplt.axis(\"off\")\n","metadata":{"execution":{"iopub.status.busy":"2022-04-02T08:19:54.894396Z","iopub.execute_input":"2022-04-02T08:19:54.894650Z","iopub.status.idle":"2022-04-02T08:20:00.800168Z","shell.execute_reply.started":"2022-04-02T08:19:54.894621Z","shell.execute_reply":"2022-04-02T08:20:00.799387Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# building the discriminator\ndiscriminator = Sequential()\ndiscriminator.add(Conv2D(32, kernel_size=3, strides=2, input_shape=(64,64,3), padding=\"same\"))\ndiscriminator.add(LeakyReLU(alpha=0.2))\ndiscriminator.add(Dropout(0.25))\ndiscriminator.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\ndiscriminator.add(ZeroPadding2D(padding=((0,1),(0,1))))\ndiscriminator.add(BatchNormalization(momentum=0.8))\ndiscriminator.add(LeakyReLU(alpha=0.2))\ndiscriminator.add(Dropout(0.25)) # can experiment by removing Dropout layer. I got better performance with it hence using it\ndiscriminator.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\ndiscriminator.add(BatchNormalization(momentum=0.8))\ndiscriminator.add(LeakyReLU(alpha=0.2))\ndiscriminator.add(Dropout(0.25))\ndiscriminator.add(Conv2D(256, kernel_size=3, strides=1, padding=\"same\"))\ndiscriminator.add(BatchNormalization(momentum=0.8))\ndiscriminator.add(LeakyReLU(alpha=0.2))\ndiscriminator.add(Dropout(0.25))\ndiscriminator.add(Conv2D(512, kernel_size=3, strides=1, padding=\"same\"))\ndiscriminator.add(BatchNormalization(momentum=0.8))\ndiscriminator.add(LeakyReLU(alpha=0.2))\ndiscriminator.add(Dropout(0.25))\ndiscriminator.add(Flatten())\ndiscriminator.add(Dense(1, activation=\"sigmoid\"))\n\ndiscriminator.summary()","metadata":{"execution":{"iopub.status.busy":"2022-04-02T08:20:55.249420Z","iopub.execute_input":"2022-04-02T08:20:55.250039Z","iopub.status.idle":"2022-04-02T08:20:55.388039Z","shell.execute_reply.started":"2022-04-02T08:20:55.249995Z","shell.execute_reply":"2022-04-02T08:20:55.387353Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"class GAN(tf.keras.Model):\n    def __init__(self, discriminator, generator, latent_dim):\n        super(GAN, self).__init__()\n        self.discriminator = discriminator\n        self.generator = generator\n        self.latent_dim = latent_dim\n\n    def compile(self, d_optimizer, g_optimizer, loss_fn):\n        super(GAN, self).compile()\n        self.d_optimizer = d_optimizer\n        self.g_optimizer = g_optimizer\n        self.loss_fn = loss_fn\n        self.d_loss_metric = tf.keras.metrics.Mean(name=\"d_loss\")\n        self.g_loss_metric = tf.keras.metrics.Mean(name=\"g_loss\")\n\n    @property\n    def metrics(self):\n        return [self.d_loss_metric, self.g_loss_metric]\n\n    def train_step(self, real_images):\n        # sample random points in the latent space\n        batch_size = tf.shape(real_images)[0]\n        noise = tf.random.normal(shape=(batch_size, self.latent_dim))\n        # decode them to fake images\n        generated_images = self.generator(noise)\n        \n        # combine them with real images\n        combined_images = tf.concat([generated_images, real_images], axis=0)\n        # assemble labels discriminating real from fake images\n        labels = tf.concat([tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))], axis=0)\n        # add random noise to the labels - important trick!\n        labels += 0.05 * tf.random.uniform(tf.shape(labels))\n        # train the discriminator\n        with tf.GradientTape() as tape:\n            predictions = self.discriminator(combined_images)\n            d_loss = self.loss_fn(labels, predictions)\n        grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n        self.d_optimizer.apply_gradients(zip(grads, self.discriminator.trainable_weights))\n\n        # sample random points in the latent space\n        noise = tf.random.normal(shape=(batch_size, self.latent_dim))\n\n        # assemble labels that say \"all real images\"\n        misleading_labels = tf.zeros((batch_size, 1))\n\n        # train the generator (note that we should *not* update the weights of the discriminator)!\n        with tf.GradientTape() as tape:\n            predictions = self.discriminator(self.generator(noise))\n            g_loss = self.loss_fn(misleading_labels, predictions)\n        grads = tape.gradient(g_loss, self.generator.trainable_weights)\n        self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\n   \n        # update metrics\n        self.d_loss_metric.update_state(d_loss)\n        self.g_loss_metric.update_state(g_loss)\n        return {\"d_loss\": self.d_loss_metric.result(), \"g_loss\": self.g_loss_metric.result()}","metadata":{"execution":{"iopub.status.busy":"2022-04-02T08:22:11.002348Z","iopub.execute_input":"2022-04-02T08:22:11.002604Z","iopub.status.idle":"2022-04-02T08:22:11.017934Z","shell.execute_reply.started":"2022-04-02T08:22:11.002575Z","shell.execute_reply":"2022-04-02T08:22:11.016819Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# defining the number of epochs\nepochs = 100\n\n# the optimizers for generator and discriminator\ndiscriminator_opt = tf.keras.optimizers.Adamax(1.5e-4,0.5)\ngenerator_opt = tf.keras.optimizers.Adamax(1.5e-4,0.5)\n\n# to compute cross entropy loss\nloss_fn = tf.keras.losses.BinaryCrossentropy()\n\n# defining GAN model\nmodel = GAN(discriminator=discriminator, generator=generator, latent_dim=latent_dim)\n\n# compiling GAN model\nmodel.compile(d_optimizer=discriminator_opt, g_optimizer=generator_opt, loss_fn=loss_fn)\n\n# fitting the GAN\nhistory = model.fit(data, epochs=epochs)","metadata":{"execution":{"iopub.status.busy":"2022-04-02T08:22:32.399653Z","iopub.execute_input":"2022-04-02T08:22:32.399920Z","iopub.status.idle":"2022-04-02T10:28:38.193557Z","shell.execute_reply.started":"2022-04-02T08:22:32.399885Z","shell.execute_reply":"2022-04-02T10:28:38.192802Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"num_img=10\n\n# a function to generate and save images\ndef Image_Generator():\n    Generated_images = []\n    noise = tf.random.normal([num_img, latent_dim]) \n    generated_image = generator(noise)\n    generated_image *= 255 \n    generated_image = generated_image.numpy()\n    for i in range(num_img):\n            img = tf.keras.preprocessing.image.array_to_img(generated_image[i])\n            Generated_images.append(img)\n            img.save(\"image{:02d}.png\".format(i)) \n    return \n\n# generating images\nImages = Image_Generator()","metadata":{"execution":{"iopub.status.busy":"2022-04-02T10:28:38.195378Z","iopub.execute_input":"2022-04-02T10:28:38.195716Z","iopub.status.idle":"2022-04-02T10:28:38.313126Z","shell.execute_reply.started":"2022-04-02T10:28:38.195665Z","shell.execute_reply":"2022-04-02T10:28:38.312360Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"Generated_path = \"./\"\nImages_generated = tf.keras.preprocessing.image_dataset_from_directory(Generated_path, label_mode = None)","metadata":{"execution":{"iopub.status.busy":"2022-04-02T10:29:02.338952Z","iopub.execute_input":"2022-04-02T10:29:02.339668Z","iopub.status.idle":"2022-04-02T10:29:02.457603Z","shell.execute_reply.started":"2022-04-02T10:29:02.339628Z","shell.execute_reply":"2022-04-02T10:29:02.456710Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(15,15))\nfor images in Images_generated.take(1):\n    for i in range(10):\n        ax = plt.subplot(5, 6, i + 1)\n        ax.imshow(images[i].numpy().astype(\"uint8\"))\n        ax.axis(\"off\")","metadata":{"execution":{"iopub.status.busy":"2022-04-02T10:31:45.161214Z","iopub.execute_input":"2022-04-02T10:31:45.162061Z","iopub.status.idle":"2022-04-02T10:31:46.095923Z","shell.execute_reply.started":"2022-04-02T10:31:45.162016Z","shell.execute_reply":"2022-04-02T10:31:46.095068Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}